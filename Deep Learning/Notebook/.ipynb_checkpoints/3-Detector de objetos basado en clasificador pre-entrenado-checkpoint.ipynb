{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• DESCARGANDO IM√ÅGENES DE MUESTRA\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/4/47/American_Eskimo_Dog.jpg: 403 Forbidden. Please comply with the User-Agent policy: https://meta.wikimedia.org/wiki/User-Agent_policy\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/6/68/Orange_tabby_cat_sitting_on_fallen_leaves.jpg: 404 Not Found\n",
      "‚úÖ Descargada: frame_0003.jpg\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/c/c1/Six_weeks_old_cat_%28aka%29.jpg: 403 Forbidden. Please comply with the User-Agent policy: https://meta.wikimedia.org/wiki/User-Agent_policy\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/5/50/Vd-ej204-vuosaari.jpg: 404 Not Found\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/a/a6/Pink_floyd_car.jpg: 404 Not Found\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/d/d5/2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg: 403 Forbidden. Please comply with the User-Agent policy: https://meta.wikimedia.org/wiki/User-Agent_policy\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/4/4f/Apple_MacBook_Air_M1.jpg: 404 Not Found\n",
      "‚ùå Error descargando https://upload.wikimedia.org/wikipedia/commons/8/88/Banana-Single.jpg: 404 Not Found\n",
      "‚úÖ Creada variaci√≥n: frame_1000.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1001.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1002.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1003.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1004.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1005.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1006.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1007.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1008.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1009.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1010.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1011.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1012.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1013.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1014.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1015.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1016.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1017.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1018.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1019.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1020.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1021.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1022.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1023.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1024.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1025.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1026.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1027.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1028.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1029.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1030.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1031.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1032.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1033.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1034.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1035.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1036.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1037.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1038.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1039.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1040.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1041.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1042.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1043.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1044.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1045.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1046.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1047.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1048.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1049.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1050.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1051.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1052.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1053.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1054.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1055.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1056.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1057.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1058.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1059.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1060.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1061.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1062.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1063.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1064.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1065.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1066.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1067.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1068.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1069.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1070.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1071.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1072.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1073.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1074.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1075.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1076.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1077.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1078.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1079.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1080.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1081.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1082.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1083.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1084.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1085.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1086.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1087.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1088.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1089.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1090.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1091.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1092.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1093.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1094.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1095.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1096.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1097.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1098.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1099.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1100.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1101.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1102.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1103.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1104.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1105.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1106.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1107.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1108.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1109.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1110.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1111.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1112.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1113.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1114.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1115.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1116.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1117.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1118.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1119.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1120.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1121.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1122.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1123.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1124.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1125.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1126.jpg\n",
      "‚úÖ Creada variaci√≥n: frame_1127.jpg\n",
      "\n",
      "üìä RESULTADOS DE CLASIFICACI√ìN\n",
      "   fotograma   clase_detectada  confianza\n",
      "0          1           Samoyed   0.946262\n",
      "1          2       pomegranate   0.858168\n",
      "2          3  golden retriever   0.845236\n",
      "3          4             tabby   0.327160\n",
      "4          5       pomegranate   0.872890\n",
      "5          6            beaver   0.996051\n",
      "6          7         tiger cat   0.863491\n",
      "7          8         tiger cat   0.518440\n",
      "8          9       pomegranate   0.761483\n",
      "9         10            beaver   0.945944\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# üöÄ Detector de Objetos basado en Clasificador Pre-entrenado\n",
    "\n",
    "Este script Python implementa un sistema para clasificar objetos en una secuencia de im√°genes (fotogramas de v√≠deo).\n",
    "Utiliza una red neuronal convolucional pre-entrenada (ResNet50 en ImageNet) para identificar el objeto m√°s probable\n",
    "en cada fotograma y reporta el grado de confianza de la clasificaci√≥n.\n",
    "\n",
    "## Funcionalidades:\n",
    "1.  **Descarga** de im√°genes de ejemplo para simular fotogramas de v√≠deo.\n",
    "2.  **Aumento de datos** simple para crear variaciones de los fotogramas.\n",
    "3.  Carga de un **clasificador pre-entrenado** (ResNet50 en ImageNet).\n",
    "4.  Realizaci√≥n de **inferencia** sobre el directorio de fotogramas.\n",
    "5.  Generaci√≥n de un **DataFrame de Pandas** con los resultados de la clasificaci√≥n.\n",
    "\n",
    "## Requisitos:\n",
    "Aseg√∫rate de tener instaladas las siguientes librer√≠as:\n",
    "-   `torch`\n",
    "-   `torchvision`\n",
    "-   `requests`\n",
    "-   `Pillow` (PIL)\n",
    "-   `pandas`\n",
    "\n",
    "Puedes instalarlas con pip:\n",
    "`pip install torch torchvision torchaudio requests Pillow pandas`\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image, ImageEnhance\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "# ‚öôÔ∏è PARTE 1 - DESCARGA DE IM√ÅGENES DE MUESTRA\n",
    "\n",
    "En esta secci√≥n, descargamos un conjunto de im√°genes desde URLs p√∫blicas.\n",
    "Estas im√°genes servir√°n como los \"fotogramas\" de un v√≠deo que el modelo procesar√°.\n",
    "Se guardar√°n en un directorio local para su posterior an√°lisis.\n",
    "\"\"\"\n",
    "\n",
    "# URLs p√∫blicas de ejemplo (puedes a√±adir m√°s si quieres)\n",
    "image_urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/4/47/American_Eskimo_Dog.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/6/68/Orange_tabby_cat_sitting_on_fallen_leaves.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/1/18/Dog_Breeds.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/c/c1/Six_weeks_old_cat_%28aka%29.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/5/50/Vd-ej204-vuosaari.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/a/a6/Pink_floyd_car.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/d/d5/2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/4/4f/Apple_MacBook_Air_M1.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/8/88/Banana-Single.jpg\"\n",
    "]\n",
    "\n",
    "save_dir = \"sample_frames\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(\"üì• DESCARGANDO IM√ÅGENES DE MUESTRA\")\n",
    "for i, url in enumerate(image_urls):\n",
    "    filename = f\"frame_{i+1:04d}.jpg\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(filepath, 'wb') as out_file:\n",
    "                shutil.copyfileobj(response.raw, out_file)\n",
    "            print(f\"‚úÖ Descargada: {filename}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error descargando {url}: {response.status_code} {response.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error descargando {url}: {e}\")\n",
    "\n",
    "\"\"\"\n",
    "# üîÅ PARTE 2 - AUMENTO DE DATOS (Data Augmentation)\n",
    "\n",
    "Para simular una mayor variedad de fotogramas o condiciones de v√≠deo,\n",
    "aplicamos t√©cnicas simples de aumento de datos a las im√°genes descargadas.\n",
    "Esto incluye ajustes de brillo, contraste y volteo horizontal.\n",
    "\"\"\"\n",
    "\n",
    "def augment_image(image):\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(random.uniform(0.7, 1.3))\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(random.uniform(0.7, 1.3))\n",
    "    return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "# Crear variaciones\n",
    "existing_files = sorted([f for f in os.listdir(save_dir) if f.endswith(\".jpg\")])\n",
    "for i, filename in enumerate(existing_files):\n",
    "    path = os.path.join(save_dir, filename)\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    variation = augment_image(image)\n",
    "    # Se a√±ade un offset de 1000 para que los nombres de archivo sean √∫nicos y se puedan ordenar f√°cilmente\n",
    "    new_filename = f\"frame_{1000 + i:04d}.jpg\"\n",
    "    variation.save(os.path.join(save_dir, new_filename))\n",
    "    print(f\"‚úÖ Creada variaci√≥n: {new_filename}\")\n",
    "\n",
    "\"\"\"\n",
    "# ü§ñ PARTE 3 - CLASIFICADOR PREENTRENADO (IMAGENET)\n",
    "\n",
    "Aqu√≠ configuramos la red neuronal convolucional pre-entrenada que usaremos para la clasificaci√≥n.\n",
    "Se utiliza ResNet50, un modelo popular entrenado en el conjunto de datos ImageNet,\n",
    "capaz de clasificar 1000 categor√≠as de objetos.\n",
    "\n",
    "Se definen las transformaciones necesarias para preparar las im√°genes para el modelo.\n",
    "\"\"\"\n",
    "\n",
    "# Transformaciones: Redimensionar, convertir a tensor y normalizar (valores est√°ndar de ImageNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Modelo: ResNet50 pre-entrenado\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval() # Poner el modelo en modo de evaluaci√≥n (importante para inferencia)\n",
    "\n",
    "# Clases de ImageNet: Descargamos la lista de las 1000 clases de ImageNet\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "labels_path = \"imagenet_classes.txt\"\n",
    "if not os.path.exists(labels_path):\n",
    "    print(\"‚¨áÔ∏è Descargando etiquetas de ImageNet...\")\n",
    "    r = requests.get(LABELS_URL)\n",
    "    with open(labels_path, 'w') as f:\n",
    "        f.write(r.text)\n",
    "    print(\"‚úÖ Etiquetas descargadas.\")\n",
    "\n",
    "with open(labels_path) as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "\"\"\"\n",
    "# üß† PARTE 4 - INFERENCIA\n",
    "\n",
    "Esta secci√≥n define la funci√≥n principal que procesa todas las im√°genes\n",
    "en el directorio especificado, realiza la clasificaci√≥n con el modelo\n",
    "pre-entrenado y recopila los resultados.\n",
    "\"\"\"\n",
    "\n",
    "def classify_images_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Clasifica las im√°genes en una carpeta dada utilizando el modelo pre-entrenado.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Ruta al directorio que contiene los fotogramas del v√≠deo.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un DataFrame con el n√∫mero de fotograma, la clase detectada\n",
    "                      y la confianza de la clasificaci√≥n.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # Obtener y ordenar los archivos para mantener el orden de los fotogramas\n",
    "    files = sorted([f for f in os.listdir(folder_path) if f.endswith('.jpg')])\n",
    "\n",
    "    print(f\"\\nüöÄ Iniciando inferencia en {len(files)} fotogramas...\")\n",
    "    for filename in files:\n",
    "        try:\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            # Aplicar transformaciones y a√±adir una dimensi√≥n de batch\n",
    "            input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad(): # Desactivar el c√°lculo de gradientes para la inferencia\n",
    "                output = model(input_tensor)\n",
    "                # Convertir logits a probabilidades\n",
    "                probs = torch.nn.functional.softmax(output[0], dim=0)\n",
    "                # Obtener la clase con la probabilidad m√°s alta\n",
    "                confidence, pred_class = torch.max(probs, 0)\n",
    "\n",
    "            # Extraer el n√∫mero de fotograma del nombre del archivo\n",
    "            frame_number = int(filename.split('_')[-1].split('.')[0])\n",
    "            class_name = classes[pred_class] # Mapear el √≠ndice a la clase legible\n",
    "\n",
    "            results.append({\n",
    "                \"fotograma\": frame_number,\n",
    "                \"clase_detectada\": class_name,\n",
    "                \"confianza\": float(confidence) # Convertir a float est√°ndar de Python\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error procesando {filename}: {e}\")\n",
    "    \n",
    "    # Crear y ordenar el DataFrame de resultados\n",
    "    df = pd.DataFrame(results).sort_values(by=\"fotograma\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "# üìä PARTE 5 - RESULTADOS Y VISUALIZACI√ìN\n",
    "\n",
    "Ejecutamos la funci√≥n de inferencia y mostramos los primeros resultados\n",
    "en formato de DataFrame de Pandas.\n",
    "\"\"\"\n",
    "\n",
    "df_resultados = classify_images_in_folder(save_dir)\n",
    "print(\"\\nüìä RESULTADOS DE CLASIFICACI√ìN\")\n",
    "print(df_resultados.head(10)) # Muestra los primeros 10 resultados del DataFrame\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
