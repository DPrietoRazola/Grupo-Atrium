{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1367d7e-44e2-4765-a218-92accf5ba413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de clases de ImageNet cargadas: 1000\n",
      "\n",
      "📥 Descargando y preparando fotogramas para video_animales_1...\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Dog_standing_in_snow.jpg/1280px-Dog_standing_in_snow.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Retriever_in_water.jpg/1280px-Retriever_in_water.jpg: 404 Not Found\n",
      "✅ Preparación de fotogramas para video_animales_1 completada.\n",
      "  🚀 Iniciando inferencia en 3 fotogramas en simulated_video_frames\\video_animales_1...\n",
      "\n",
      "📥 Descargando y preparando fotogramas para video_vehiculos_1...\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg/1280px-Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Car_with_a_blue_sky.jpg/1280px-Car_with_a_blue_sky.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg/1280px-2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg: 404 Not Found\n",
      "✅ Preparación de fotogramas para video_vehiculos_1 completada.\n",
      "⚠️ No se encontraron imágenes en simulated_video_frames\\video_vehiculos_1. Saltando clasificación.\n",
      "\n",
      "📥 Descargando y preparando fotogramas para video_comida_1...\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Vegan_food_at_restaurant_%28Pexels%29.jpg/1280px-Vegan_food_at_restaurant_%28Pexels%29.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Pizza_with_peperoni.jpg/1280px-Pizza_with_peperoni.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Vegan_food_at_restaurant_%28Pexels%29.jpg/1280px-Vegan_food_at_restaurant_%28Pexels%29.jpg: 404 Not Found\n",
      "✅ Preparación de fotogramas para video_comida_1 completada.\n",
      "⚠️ No se encontraron imágenes en simulated_video_frames\\video_comida_1. Saltando clasificación.\n",
      "\n",
      "📥 Descargando y preparando fotogramas para video_animales_2...\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Dog_standing_in_snow.jpg/1280px-Dog_standing_in_snow.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Retriever_in_water.jpg/1280px-Retriever_in_water.jpg: 404 Not Found\n",
      "✅ Preparación de fotogramas para video_animales_2 completada.\n",
      "  🚀 Iniciando inferencia en 6 fotogramas en simulated_video_frames\\video_animales_2...\n",
      "\n",
      "📥 Descargando y preparando fotogramas para video_variado_1...\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Dog_standing_in_snow.jpg/1280px-Dog_standing_in_snow.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Car_with_a_blue_sky.jpg/1280px-Car_with_a_blue_sky.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Vegan_food_at_restaurant_%28Pexels%29.jpg/1280px-Vegan_food_at_restaurant_%28Pexels%29.jpg: 404 Not Found\n",
      "✅ Preparación de fotogramas para video_variado_1 completada.\n",
      "⚠️ No se encontraron imágenes en simulated_video_frames\\video_variado_1. Saltando clasificación.\n",
      "\n",
      "📥 Descargando y preparando fotogramas para video_vehiculos_2...\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg/1280px-Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Car_with_a_blue_sky.jpg/1280px-Car_with_a_blue_sky.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg/1280px-2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg: 404 Not Found\n",
      "  ❌ Error descargando https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg/1280px-Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg: 404 Not Found\n",
      "✅ Preparación de fotogramas para video_vehiculos_2 completada.\n",
      "⚠️ No se encontraron imágenes en simulated_video_frames\\video_vehiculos_2. Saltando clasificación.\n",
      "\n",
      "✅ Generación de DataFrames de inferencia por vídeo completada.\n",
      "\n",
      "⚙️ Generando características agregadas para cada vídeo para el clasificador final...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "1000 columns passed, passed data had 998 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:934\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:981\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    984\u001b[0m     )\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 1000 columns passed, passed data had 998 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 291\u001b[0m\n\u001b[0;32m    288\u001b[0m     y_video_types\u001b[38;5;241m.\u001b[39mappend(video_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_type\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# Convertir a DataFrame de Pandas para el entrenamiento\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_video_features, columns\u001b[38;5;241m=\u001b[39mall_imagenet_classes)\n\u001b[0;32m    292\u001b[0m y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(y_video_types, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 DataFrame de características de vídeos (primeras 5 filas y 5 columnas):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 782\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         data,\n\u001b[0;32m    786\u001b[0m         columns,\n\u001b[0;32m    787\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    788\u001b[0m         dtype,\n\u001b[0;32m    789\u001b[0m     )\n\u001b[0;32m    790\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    791\u001b[0m         arrays,\n\u001b[0;32m    792\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    795\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 498\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    499\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:840\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    837\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    838\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 840\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:937\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    940\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 1000 columns passed, passed data had 998 columns"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image, ImageEnhance\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# ==============================================================================\n",
    "# ⚙️ PARTE 1 - PREPARACIÓN DE DATOS (Simulación de Fotogramas de Vídeo)\n",
    "# ==============================================================================\n",
    "\n",
    "# URLs públicas de ejemplo (actualizadas para mayor fiabilidad)\n",
    "image_urls_base = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Dog_standing_in_snow.jpg/1280px-Dog_standing_in_snow.jpg\", # Perro\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_March_2010-1.jpg/1280px-Cat_March_2010-1.jpg\", # Gato\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Retriever_in_water.jpg/1280px-Retriever_in_water.jpg\", # Perro en agua\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg/1280px-Seaside_Railway_Station%2C_Ryde_Pier_Head_%28107774%29.jpg\", # Tren\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Car_with_a_blue_sky.jpg/1280px-Car_with_a_blue_sky.jpg\", # Coche\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg/1280px-2019_Toyota_Corolla_Icon_Tech_VVT-i_1.8_Front.jpg\", # Coche (frontal)\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Vegan_food_at_restaurant_%28Pexels%29.jpg/1280px-Vegan_food_at_restaurant_%28Pexels%29.jpg\", # Comida (plato)\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Pizza_with_peperoni.jpg/1280px-Pizza_with_peperoni.jpg\" # Pizza\n",
    "]\n",
    "\n",
    "# Directorio base para guardar los fotogramas simulados\n",
    "base_frames_dir = \"simulated_video_frames\"\n",
    "os.makedirs(base_frames_dir, exist_ok=True)\n",
    "\n",
    "def download_and_augment_frames(urls, video_name, num_variations=2):\n",
    "    \"\"\"\n",
    "    Descarga imágenes y crea variaciones para simular fotogramas de un vídeo.\n",
    "    Guarda los fotogramas en una subcarpeta bajo base_frames_dir.\n",
    "    \"\"\"\n",
    "    video_frames_dir = os.path.join(base_frames_dir, video_name)\n",
    "    os.makedirs(video_frames_dir, exist_ok=True)\n",
    "\n",
    "    # Añadir un User-Agent a los headers de la solicitud para evitar errores 403 Forbidden\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    print(f\"\\n📥 Descargando y preparando fotogramas para {video_name}...\")\n",
    "    frame_counter = 1\n",
    "    for url in urls:\n",
    "        filename = f\"frame_{frame_counter:04d}.jpg\"\n",
    "        filepath = os.path.join(video_frames_dir, filename)\n",
    "        try:\n",
    "            # Pasar los headers a la solicitud get\n",
    "            response = requests.get(url, stream=True, headers=headers, timeout=10) # Añadir timeout\n",
    "            if response.status_code == 200:\n",
    "                with open(filepath, 'wb') as out_file:\n",
    "                    shutil.copyfileobj(response.raw, out_file)\n",
    "\n",
    "                # Crear variaciones (aumento de datos)\n",
    "                image = Image.open(filepath).convert(\"RGB\")\n",
    "                for v in range(num_variations):\n",
    "                    # Asegurar que las variaciones tienen un nombre de archivo único\n",
    "                    new_filename = f\"frame_{frame_counter:04d}_var{v+1}.jpg\"\n",
    "                    variation = augment_image(image)\n",
    "                    variation.save(os.path.join(video_frames_dir, new_filename))\n",
    "                frame_counter += 1\n",
    "            else:\n",
    "                print(f\"  ❌ Error descargando {url}: {response.status_code} {response.reason}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  ❌ Error de solicitud para {url}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error general al procesar {url}: {e}\")\n",
    "    print(f\"✅ Preparación de fotogramas para {video_name} completada.\")\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Aplica transformaciones simples a una imagen para aumento de datos.\"\"\"\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(random.uniform(0.8, 1.2)) # Rango más conservador\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "# ==============================================================================\n",
    "# 🤖 PARTE 2 - CLASIFICADOR DE OBJETOS (Pre-entrenado en ImageNet)\n",
    "# ==============================================================================\n",
    "\n",
    "# Transformaciones necesarias para las imágenes antes de pasarlas al modelo\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # ResNet50 espera imágenes de 224x224\n",
    "    transforms.ToTensor(),         # Convierte la imagen a un tensor de PyTorch\n",
    "    transforms.Normalize(          # Normaliza con los valores estándar de ImageNet\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Cargar el modelo ResNet50 pre-entrenado en ImageNet\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.eval() # Poner el modelo en modo de evaluación (desactiva dropout, etc., para inferencia)\n",
    "\n",
    "# Descargar la lista de las 1000 clases de ImageNet si no existe\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "labels_path = \"imagenet_classes.txt\"\n",
    "if not os.path.exists(labels_path):\n",
    "    print(\"⬇️ Descargando etiquetas de ImageNet...\")\n",
    "    r = requests.get(LABELS_URL)\n",
    "    with open(labels_path, 'w') as f:\n",
    "        f.write(r.text)\n",
    "    print(\"✅ Etiquetas descargadas.\")\n",
    "\n",
    "with open(labels_path) as f:\n",
    "    all_imagenet_classes = [line.strip() for line in f.readlines()]\n",
    "print(f\"Total de clases de ImageNet cargadas: {len(all_imagenet_classes)}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 🧠 PARTE 3 - INFERENCIA DE OBJETOS EN FOTOGRAMAS\n",
    "# ==============================================================================\n",
    "\n",
    "def classify_frames_in_folder(folder_path, classes_list):\n",
    "    \"\"\"\n",
    "    Clasifica los objetos en cada fotograma dentro de una carpeta dada.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Ruta al directorio que contiene los fotogramas (imágenes JPG).\n",
    "        classes_list (list): Lista de todas las clases posibles del modelo (ej. ImageNet).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un DataFrame con 'fotograma', 'clase_detectada' y 'confianza'.\n",
    "                      Retorna un DataFrame vacío si la carpeta no contiene imágenes.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # Obtener y ordenar los archivos para mantener el orden de los fotogramas\n",
    "    files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "    if not files:\n",
    "        print(f\"⚠️ No se encontraron imágenes en {folder_path}. Saltando clasificación.\")\n",
    "        return pd.DataFrame(columns=[\"fotograma\", \"clase_detectada\", \"confianza\"])\n",
    "\n",
    "    print(f\"  🚀 Iniciando inferencia en {len(files)} fotogramas en {folder_path}...\")\n",
    "    for i, filename in enumerate(files):\n",
    "        try:\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            input_tensor = transform(image).unsqueeze(0) # Añadir dimensión de batch\n",
    "\n",
    "            with torch.no_grad(): # Desactivar cálculo de gradientes\n",
    "                output = model(input_tensor)\n",
    "                probs = torch.nn.functional.softmax(output[0], dim=0)\n",
    "                confidence, pred_class_idx = torch.max(probs, 0)\n",
    "\n",
    "            # Usamos el índice i+1 como número de fotograma para esta secuencia específica\n",
    "            frame_number = i + 1\n",
    "            class_name = classes_list[pred_class_idx]\n",
    "\n",
    "            results.append({\n",
    "                \"fotograma\": frame_number,\n",
    "                \"clase_detectada\": class_name,\n",
    "                \"confianza\": float(confidence)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ Error procesando {filename} en {folder_path}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(by=\"fotograma\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# 📊 PARTE 4 - SIMULACIÓN DE MÚLTIPLES VÍDEOS Y SUS TIPOS (Dataset para ML)\n",
    "# ==============================================================================\n",
    "\n",
    "# Definición de vídeos de ejemplo y sus etiquetas de tipo\n",
    "simulated_videos_data = [\n",
    "    {\n",
    "        \"name\": \"video_animales_1\",\n",
    "        \"type\": \"Animales\",\n",
    "        \"urls\": image_urls_base[0:3] # Perro, gato, perro en agua\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"video_vehiculos_1\",\n",
    "        \"type\": \"Vehiculos\",\n",
    "        \"urls\": image_urls_base[3:6] # Tren, coche, coche (frontal)\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"video_comida_1\",\n",
    "        \"type\": \"Comida\",\n",
    "        \"urls\": image_urls_base[6:8] + [image_urls_base[6]] # Comida, pizza, comida\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"video_animales_2\",\n",
    "        \"type\": \"Animales\",\n",
    "        \"urls\": [image_urls_base[0], image_urls_base[1], image_urls_base[2], image_urls_base[1]] # Mas animales\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"video_variado_1\",\n",
    "        \"type\": \"Variado\",\n",
    "        \"urls\": [image_urls_base[0], image_urls_base[4], image_urls_base[6]] # Animal, coche, comida\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"video_vehiculos_2\",\n",
    "        \"type\": \"Vehiculos\",\n",
    "        \"urls\": [image_urls_base[3], image_urls_base[4], image_urls_base[5], image_urls_base[3]] # Mas vehiculos\n",
    "    }\n",
    "    # Añade más vídeos simulados aquí para un dataset más grande y diverso\n",
    "]\n",
    "\n",
    "video_inferences = [] # Aquí guardaremos {id_video, df_inferencias, tipo_video}\n",
    "\n",
    "for video_info in simulated_videos_data:\n",
    "    # 1. Descargar y aumentar fotogramas para el vídeo actual\n",
    "    download_and_augment_frames(video_info[\"urls\"], video_info[\"name\"])\n",
    "\n",
    "    # 2. Clasificar objetos en los fotogramas de este vídeo\n",
    "    video_frames_path = os.path.join(base_frames_dir, video_info[\"name\"])\n",
    "    df_inferencias_video = classify_frames_in_folder(video_frames_path, all_imagenet_classes)\n",
    "\n",
    "    # 3. Guardar las inferencias junto con el tipo de vídeo\n",
    "    video_inferences.append({\n",
    "        \"video_id\": video_info[\"name\"],\n",
    "        \"df_inferencias\": df_inferencias_video,\n",
    "        \"video_type\": video_info[\"type\"]\n",
    "    })\n",
    "\n",
    "print(\"\\n✅ Generación de DataFrames de inferencia por vídeo completada.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ⚙️ PARTE 5 - INGENIERÍA DE CARACTERÍSTICAS PARA CLASIFICACIÓN DE VÍDEOS\n",
    "# ==============================================================================\n",
    "\n",
    "def create_video_features(video_df, all_possible_classes_list):\n",
    "    \"\"\"\n",
    "    Crea un vector de características de tamaño fijo para un vídeo.\n",
    "    Calcula la \"importancia\" de cada clase basada en frecuencia y confianza media.\n",
    "\n",
    "    Args:\n",
    "        video_df (pd.DataFrame): DataFrame de inferencias de objetos de un solo vídeo.\n",
    "        all_possible_classes_list (list): Lista exhaustiva de todas las clases que el\n",
    "            clasificador de objetos puede detectar (ej. las 1000 de ImageNet).\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario donde las claves son las clases y los valores son su \"importancia\"\n",
    "            en el vídeo. Si una clase no aparece, su importancia es 0.\n",
    "    \"\"\"\n",
    "    features = {cls: 0.0 for cls in all_possible_classes_list}\n",
    "\n",
    "    if video_df.empty:\n",
    "        return features\n",
    "\n",
    "    # Número total de fotogramas únicos en el vídeo (para normalización)\n",
    "    total_unique_frames = video_df['fotograma'].nunique()\n",
    "    if total_unique_frames == 0:\n",
    "        return features  # Evitar división por cero si no hay fotogramas clasificados\n",
    "\n",
    "    # Agrupar por clase detectada\n",
    "    grouped_by_class = video_df.groupby('clase_detectada').agg(\n",
    "        count=('clase_detectada', 'size'),          # Número de veces que aparece la clase\n",
    "        sum_confidence=('confianza', 'sum')         # Suma de las confianzas para esa clase\n",
    "    ).reset_index()\n",
    "\n",
    "    for _, row in grouped_by_class.iterrows():\n",
    "        cls = row['clase_detectada']\n",
    "        count = row['count']\n",
    "        sum_confidence = row['sum_confidence']\n",
    "\n",
    "        # Calcular frecuencia normalizada\n",
    "        freq_normalized = count / total_unique_frames\n",
    "\n",
    "        # Calcular confianza media para esa clase\n",
    "        avg_confidence = sum_confidence / count\n",
    "\n",
    "        # Combinar frecuencia y confianza. Puedes experimentar con esta fórmula.\n",
    "        # Aquí, simplemente el producto.\n",
    "        importance = freq_normalized * avg_confidence\n",
    "\n",
    "        # Asignar la importancia solo si la clase está en nuestra lista global de clases\n",
    "        if cls in features:\n",
    "            features[cls] = importance\n",
    "\n",
    "    return features\n",
    "\n",
    "# Generar el dataset final de características (X) y etiquetas (y) para el clasificador de vídeos\n",
    "X_video_features = []\n",
    "y_video_types = []\n",
    "\n",
    "print(\"\\n⚙️ Generando características agregadas para cada vídeo para el clasificador final...\")\n",
    "for video_info in video_inferences:\n",
    "    features_dict = create_video_features(video_info[\"df_inferencias\"], all_imagenet_classes)\n",
    "    X_video_features.append(list(features_dict.values()))\n",
    "    y_video_types.append(video_info[\"video_type\"])\n",
    "\n",
    "# Convertir a DataFrame de Pandas para el entrenamiento\n",
    "X = pd.DataFrame(X_video_features, columns=all_imagenet_classes)\n",
    "y = pd.Series(y_video_types, name=\"video_type\")\n",
    "\n",
    "print(\"\\n📊 DataFrame de características de vídeos (primeras 5 filas y 5 columnas):\")\n",
    "if not X.empty:\n",
    "    print(X.iloc[:, :min(5, X.shape[1])].head()) # Muestra solo las primeras 5 columnas o menos si hay menos\n",
    "else:\n",
    "    print(\"DataFrame de características X está vacío. No se pudieron generar características.\")\n",
    "print(\"\\n🎯 Etiquetas de tipo de vídeo:\")\n",
    "print(y)\n",
    "\n",
    "# ==============================================================================\n",
    "# 🤖 PARTE 6 - ENTRENAMIENTO Y EVALUACIÓN DEL CLASIFICADOR DE VÍDEOS\n",
    "# ==============================================================================\n",
    "\n",
    "# Solo proceder si X no está vacío y tiene suficientes muestras para split\n",
    "if not X.empty and len(X) > 1 and len(y.unique()) > 1: # Necesitas al menos 2 muestras y 2 clases para stratify\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"\\nTotal de vídeos para entrenamiento: {len(X_train)}\")\n",
    "    print(f\"Total de vídeos para prueba: {len(X_test)}\")\n",
    "\n",
    "    # Inicializar y entrenar el clasificador de tipo de vídeo\n",
    "    video_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    print(\"\\n💪 Entrenando el clasificador de tipo de vídeo...\")\n",
    "    video_classifier.fit(X_train, y_train)\n",
    "    print(\"✅ Entrenamiento completado.\")\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred = video_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluar el rendimiento del clasificador\n",
    "    print(\"\\n✅ Evaluación del Clasificador de Tipo de Vídeo:\")\n",
    "    print(f\"Precisión (Accuracy): {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ No hay suficientes datos o clases para entrenar y evaluar el clasificador de vídeos. Necesitas más vídeos simulados o reales con diferentes tipos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe5bd1-5b4b-4e5c-94ca-f4632178bc62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
